{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poomshift/ComfyUI-Colab-Alchemist/blob/main/comfy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f6f22ad383364436a1767369f67fb524",
            "d20c0ec2528f41548a205a472305645c",
            "ca641790770546f6a84dca8aa6a33ae3",
            "740037f160144a90910aa4be6c502278",
            "ea4e091f950142a4bb6e793f0a3b56f0",
            "224e5b6240c7469db0149e966626f109"
          ]
        },
        "id": "om8BWvdWJgoN",
        "outputId": "c504cc4a-2999-4885-c377-cac79aaa48e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "740037f160144a90910aa4be6c502278"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown #ติดตั้ง ComfyUI | Models | Custom nodes\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Javascript\n",
        "import ipywidgets as widgets\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "\n",
        "\n",
        "#ติดตั้ง comfy\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI\n",
        "\n",
        "#ติดตั้ง Dependencies\n",
        "%cd ComfyUI\n",
        "!apt -y install -qq aria2\n",
        "!pip install xformers!=0.0.18 -r requirements.txt  --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "#cloudflare tunnel\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "#Checkpoints\n",
        "%cd /content/ComfyUI/models/checkpoints\n",
        "\n",
        "#@markdown Checkpoints เริ่มต้น\n",
        "LEOSAM_HelloWorld_XL_V7 = True # @param {type:\"boolean\"}\n",
        "if LEOSAM_HelloWorld_XL_V7 == True:\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://civitai.com/api/download/models/570138\n",
        "else:\n",
        "  ()\n",
        "\n",
        "PonyDiffusionV6XL = False # @param {type:\"boolean\"}\n",
        "if PonyDiffusionV6XL == True:\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/Magamanny/Pony-Diffusion-V6-XL/resolve/main/ponyDiffusionV6XL_v6StartWithThisOne.safetensors -o PonyDiffusionV6XL.safetensors\n",
        "else:\n",
        "  ()\n",
        "\n",
        "majicMIX_realistic_V7 = True # @param {type:\"boolean\"}\n",
        "if majicMIX_realistic_V7 == True:\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://civitai.com/api/download/models/176425 -o majicmixRealisticV7.safetensors\n",
        "else:\n",
        "  ()\n",
        "\n",
        "#@markdown ใส่โมเดลเพิ่มเติม\n",
        "#Civitai API\n",
        "Civitai_API_key = \"ใส่ API key จาก civitai.com ถ้าต้องการใส่โมเดลเพิ่มเติม\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown Checkpoint ลิงค์จาก Civitai\n",
        "\n",
        "Checkpoint_01 = \"\"  #@param {type:\"string\"}\n",
        "Checkpoint_02 = \"\"  #@param {type:\"string\"}\n",
        "Checkpoint_03 = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# Function to construct and execute download command\n",
        "def download_checkpoint(checkpoint_url, api_key):\n",
        "    if checkpoint_url:\n",
        "        download_command = f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{checkpoint_url}?token={api_key}\"'\n",
        "        !{download_command}\n",
        "        print(f\"{checkpoint_url}?token={api_key}\")\n",
        "    else:\n",
        "        print(\"Checkpoint URL is blank, skipping download.\")\n",
        "\n",
        "# Execute download commands for each checkpoint\n",
        "download_checkpoint(Checkpoint_01, Civitai_API_key)\n",
        "download_checkpoint(Checkpoint_02, Civitai_API_key)\n",
        "download_checkpoint(Checkpoint_03, Civitai_API_key)\n",
        "\n",
        "#Loras\n",
        "%cd /content/ComfyUI/models/loras\n",
        "\n",
        "# @markdown LoRA ลิงค์จาก Civitai\n",
        "\n",
        "LoRA_01 = \"https://civitai.com/api/download/models/132876\"  #@param {type:\"string\"}\n",
        "LoRA_02 = \"\"  #@param {type:\"string\"}\n",
        "LoRA_03 = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# Function to construct and execute download command\n",
        "def download_lora(lora_url, api_key):\n",
        "    if lora_url:\n",
        "        download_command = f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{lora_url}?token={api_key}\"'\n",
        "        !{download_command}\n",
        "        print(f\"{lora_url}?token={api_key}\")\n",
        "    else:\n",
        "        print(\"Checkpoint URL is blank, skipping download.\")\n",
        "\n",
        "# Execute download commands for each checkpoint\n",
        "download_lora(LoRA_01, Civitai_API_key)\n",
        "download_lora(LoRA_02, Civitai_API_key)\n",
        "download_lora(LoRA_03, Civitai_API_key)\n",
        "\n",
        "%cd /content/ComfyUI/models/vae\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://civitai.com/api/download/models/290640?type=VAE&format=SafeTensor -o SDXL-Vae.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://civitai.com/api/download/models/311162 -o SD-1-5-Vae.safetensors\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/xinsir/controlnet-union-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors -d /content/ComfyUI/models/controlnet -o controlnet-union-sdxl.safetensors\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Impact-Pack\n",
        "!git clone https://github.com/cubiq/ComfyUI_essentials\n",
        "!git clone https://github.com/Fannovel16/comfyui_controlnet_aux\n",
        "!git clone https://github.com/nicofdga/DZ-FaceDetailer\n",
        "!git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus\n",
        "\n",
        "#ipadapter models\n",
        "%cd /content/ComfyUI/models/clip_vision\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors  -o CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors  -o CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors\n",
        "\n",
        "%cd /content/ComfyUI/models\n",
        "\n",
        "!mkdir ipadapter\n",
        "\n",
        "%cd /content/ComfyUI/models/ipadapter\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.safetensors  -o ip-adapter_sd15.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_light_v11.bin  -o ip-adapter_sd15_light_v11.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus_sd15.safetensors  -o ip-adapter-plus_sd15.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.safetensors  -o ip-adapter-plus-face_sd15.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-full-face_sd15.safetensors  -o ip-adapter-full-face_sd15.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_vit-G.safetensors  -o ip-adapter_sd15_vit-G.safetensors\n",
        "\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors  -o ip-adapter_sdxl_vit-h.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus_sdxl_vit-h.safetensors  -o ip-adapter-plus_sdxl_vit-h.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus-face_sdxl_vit-h.safetensors  -o ip-adapter-plus-face_sdxl_vit-h.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -c https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl.safetensors  -o ip-adapter_sdxl.safetensors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTB04obflHvZ"
      },
      "outputs": [],
      "source": [
        "!wget -qO- cli.runpod.net | sudo bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYVf1tz_nvxo"
      },
      "outputs": [],
      "source": [
        "%cd /content/ComfyUI/models/loras\n",
        "!runpodctl receive 7138-system-monkey-fractal-6\n",
        "%cd /content/ComfyUI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wmWPJDbAY14",
        "outputId": "73fe27e4-5c94-4326-c81d-00117f926f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2024-07-11 20:25:19.442832\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** Log path: /content/ComfyUI/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.9 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 52217 MB\n",
            "pytorch version: 2.3.1+cu118\n",
            "xformers version: 0.0.27+cu118\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers cross attention\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "/content/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/dwpose.py:26: UserWarning: DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\n",
            "  warnings.warn(\"DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\")\n",
            "### Loading: ComfyUI-Impact-Pack (V5.18.13)\n",
            "### Loading: ComfyUI-Impact-Pack (Subpack: V0.6)\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "[Impact Pack] Wildcards loading done.\n",
            "FaceDetailer: Model directory already exists\n",
            "FaceDetailer: Model already exists\n",
            "### Loading: ComfyUI-Manager (V2.46.3)\n",
            "### ComfyUI Revision: 2355 [f45157e3] | Released on '2024-07-11'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI_essentials\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Impact-Pack\n",
            "   0.6 seconds: /content/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   2.8 seconds: /content/ComfyUI/custom_nodes/DZ-FaceDetailer\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "This is the URL to access ComfyUI: https://characterized-figure-suffered-dui.trycloudflare.com                               |\n",
            "FETCH DATA from: /content/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "got prompt\n",
            "model_type EPS\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "\u001b[33mINFO: Clip Vision model loaded from /content/ComfyUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\u001b[0m\n",
            "\u001b[33mINFO: IPAdapter model loaded from /content/ComfyUI/models/ipadapter/ip-adapter-plus_sdxl_vit-h.safetensors\u001b[0m\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:16<00:00,  1.24it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "Prompt executed in 29.46 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "got prompt\n",
            "Prompt executed in 26.73 seconds\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 22.95 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "Prompt executed in 23.21 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.39it/s]\n",
            "Prompt executed in 19.79 seconds\n",
            "got prompt\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.46it/s]\n",
            "Prompt executed in 16.42 seconds\n",
            "got prompt\n",
            "Prompt executed in 0.00 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: Clip Vision model loaded from /content/ComfyUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\u001b[0m\n",
            "\u001b[33mINFO: IPAdapter model loaded from /content/ComfyUI/models/ipadapter/ip-adapter-plus_sdxl_vit-h.safetensors\u001b[0m\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.40it/s]\n",
            "Prompt executed in 20.02 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.46it/s]\n",
            "Prompt executed in 17.23 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.43it/s]\n",
            "Prompt executed in 19.48 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.45it/s]\n",
            "Prompt executed in 18.71 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.45it/s]\n",
            "Prompt executed in 20.31 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.42it/s]\n",
            "Prompt executed in 23.17 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "!!! Exception during processing!!! InvertMask.invert() missing 1 required positional argument: 'mask'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 151, in recursive_execute\n",
            "    output_data, output_ui = get_output_data(obj, input_data_all)\n",
            "  File \"/content/ComfyUI/execution.py\", line 81, in get_output_data\n",
            "    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)\n",
            "  File \"/content/ComfyUI/execution.py\", line 69, in map_node_over_list\n",
            "    results.append(getattr(obj, func)())\n",
            "TypeError: InvertMask.invert() missing 1 required positional argument: 'mask'\n",
            "\n",
            "Prompt executed in 0.36 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.40it/s]\n",
            "Prompt executed in 23.02 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.47it/s]\n",
            "Prompt executed in 18.85 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.40it/s]\n",
            "Prompt executed in 19.20 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.38it/s]\n",
            "Prompt executed in 22.89 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.40it/s]\n",
            "Prompt executed in 17.43 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.42it/s]\n",
            "Prompt executed in 19.30 seconds\n",
            "got prompt\n",
            "Failed to validate prompt for output 17:\n",
            "* InvertMask 19:\n",
            "  - Required input is missing: mask\n",
            "Output will be ignored\n",
            "model_type EPS\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.45it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "Prompt executed in 26.23 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.42it/s]\n",
            "Prompt executed in 21.15 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.40it/s]\n",
            "Prompt executed in 21.14 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.41it/s]\n",
            "Prompt executed in 19.44 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.39it/s]\n",
            "Prompt executed in 18.04 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:13<00:00,  1.43it/s]\n",
            "Prompt executed in 19.25 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.41it/s]\n",
            "Prompt executed in 19.05 seconds\n",
            "got prompt\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "100% 20/20 [00:14<00:00,  1.39it/s]\n",
            "Prompt executed in 17.88 seconds\n",
            "\n",
            "Stopped server\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ComfyUI\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOs9pLayR6bVaDLtk1zHdWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6f22ad383364436a1767369f67fb524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_d20c0ec2528f41548a205a472305645c",
            "style": "IPY_MODEL_ca641790770546f6a84dca8aa6a33ae3",
            "tooltip": ""
          }
        },
        "d20c0ec2528f41548a205a472305645c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca641790770546f6a84dca8aa6a33ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "740037f160144a90910aa4be6c502278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_ea4e091f950142a4bb6e793f0a3b56f0",
            "style": "IPY_MODEL_224e5b6240c7469db0149e966626f109",
            "tooltip": ""
          }
        },
        "ea4e091f950142a4bb6e793f0a3b56f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224e5b6240c7469db0149e966626f109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}